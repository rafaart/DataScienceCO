{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO34OcbdhHAYG5+zLVYHTdi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaart/DataScienceCO/blob/develop/otimiza%C3%A7%C3%A3oCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIYQXUP-eiOw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import mixed_precision\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar o dataset\n",
        "!pip install kaggle\n",
        "!kaggle datasets download -d arbazkhan971/cuhk-face-sketch-database-cufs --force\n",
        "!unzip -oq \"cuhk-face-sketch-database-cufs.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvwYa192_5VG",
        "outputId": "aab7b6df-c9b1-43f3-8b52-09b05f9433ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/arbazkhan971/cuhk-face-sketch-database-cufs\n",
            "License(s): copyright-authors\n",
            "Downloading cuhk-face-sketch-database-cufs.zip to /content\n",
            " 84% 95.0M/113M [00:00<00:00, 141MB/s]\n",
            "100% 113M/113M [00:00<00:00, 132MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = 'photos'\n",
        "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
        "\n",
        "# Divide os arquivos em conjuntos de treino e teste (80% treino, 20% teste)\n",
        "train_files, test_files = train_test_split(image_files, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "JlUuYiMf_tgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento das imagens degradadas\n",
        "\n",
        "X_train = []\n",
        "for image_file in train_files:\n",
        "  try:\n",
        "    img = Image.open(image_file)\n",
        "    img = img.resize((25, 32))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    X_train.append(img_array)\n",
        "  except Exception as e:\n",
        "    print(f\"Erro ao carregar imagem {image_file}: {e}\")\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "plt.imshow(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "8PFTPEyP_nDg",
        "outputId": "8006bf5a-24ff-48ed-9e28-49bdfbf014a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a1cf95c33d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento das imagens boas\n",
        "\n",
        "X_good = []\n",
        "for image_file in train_files:\n",
        "  try:\n",
        "    img = Image.open(image_file)\n",
        "    img = img.resize((200, 256))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    X_good.append(img_array)\n",
        "  except Exception as e:\n",
        "    print(f\"Erro ao carregar imagem {image_file}: {e}\")\n",
        "\n",
        "X_good = np.array(X_good)\n",
        "\n",
        "plt.imshow(X_good[0])"
      ],
      "metadata": {
        "id": "8BZLdcDtvzNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "axZzSRAxe31j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir o modelo CNN\n",
        "\"\"\"\n",
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(32, 25, 3)))  # Dimensões originais das imagens \"boas\"\n",
        "\n",
        "    # Camadas convolucionais e de upsampling\n",
        "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='sigmoid'))  # Saída de 3 canais (RGB)\n",
        "\n",
        "    return model\n",
        "\"\"\"\n",
        "\n",
        "def build_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Input da imagem \"ruim\" com dimensões 32x24\n",
        "    model.add(layers.Input(shape=(32, 25, 3)))\n",
        "\n",
        "    # Primeira camada convolucional\n",
        "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Aumentando as dimensões progressivamente com camadas de upsampling\n",
        "    model.add(layers.UpSampling2D((2, 2)))  # 64x50\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    model.add(layers.UpSampling2D((2, 2)))  # 128x100\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    model.add(layers.UpSampling2D((2, 2)))  # 256x200\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Ajustando para a dimensão final (250x200)\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "\n",
        "    # Saída com 3 canais (RGB) e dimensão final 250x200\n",
        "    model.add(layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "AvvP64_3F9uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir o modelo\n",
        "model = build_model()"
      ],
      "metadata": {
        "id": "X67OWdjqGh7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "eWxD3xvmGgAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_good.shape)  # Verifique a forma das imagens \"boas\"\n",
        "print(X_train.shape) # Verifique a forma das imagens \"ruins\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3OLQLniXXD1",
        "outputId": "b368bd59-0600-4a65-b827-eb745f2887da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 250, 200, 3)\n",
            "(150, 32, 25, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento do modelo\n",
        "model.fit(X_train, X_good, epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "WPVvR-UrGQEi",
        "outputId": "1ca3df4e-a604-4ce8-fd1b-68c4e19712c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Dimensions must be equal, but are 250 and 256 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_1, sequential_1/conv2d_6_1/Sigmoid)' with input shapes: [?,250,200,3], [?,256,200,3].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8dfe6018bb77>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Treinamento do modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_good\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqueeze_or_expand_to_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 250 and 256 for '{{node compile_loss/mean_squared_error/sub}} = Sub[T=DT_FLOAT](data_1, sequential_1/conv2d_6_1/Sigmoid)' with input shapes: [?,250,200,3], [?,256,200,3]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação do modelo\n",
        "# Testar com algumas imagens do conjunto de teste\n",
        "for test_file in test_files[:5]:  # Testar nas primeiras 5 imagens\n",
        "    img = Image.open(test_file)\n",
        "    img = img.resize((25, 32))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = img_array.reshape(1, 32, 25, 3)  # Adiciona dimensão para o batch\n",
        "\n",
        "    # Prever a imagem\n",
        "    pred = model.predict(img_array)\n",
        "\n",
        "    # Visualizar a imagem original e a prevista\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.imshow(img_array.squeeze())\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Imagem Melhorada\")\n",
        "    plt.imshow(pred.squeeze())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jJDRXmoKGHfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tentativa de melhoria no codigo\n"
      ],
      "metadata": {
        "id": "OchxoIpiGCJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajuste automático de learning rate\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "metadata": {
        "id": "bXaYU7rmezpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning com VGG16\n",
        "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = layers.Flatten()(vgg.output)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "output = layers.Dense(3, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=vgg.input, outputs=output)"
      ],
      "metadata": {
        "id": "IWj3u5k9ewEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar o modelo\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "idf7sFuzetrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks para salvar checkpoints e early stopping\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "Trjdhd17epgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento com data augmentation e callbacks\n",
        "# Geradores separados para treino e validação\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# O gerador de validação não precisa de augmentation\n",
        "validation_datagen = ImageDataGenerator()\n",
        "\n",
        "# Criando os geradores\n",
        "train_generator = train_datagen.flow(X_train, X_train, batch_size=32)\n",
        "validation_generator = validation_datagen.flow(X_train, X_train, batch_size=32)\n",
        "\n",
        "# Ajuste no fit: passar diretamente os geradores\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=50,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "cApNQpinemll",
        "outputId": "3247a351-159d-42d3-8365-6a22698dfc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 32, 25, 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-719af2762cb7>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Ajuste no fit: passar diretamente os geradores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m     20\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 32, 25, 3)"
          ]
        }
      ]
    }
  ]
}